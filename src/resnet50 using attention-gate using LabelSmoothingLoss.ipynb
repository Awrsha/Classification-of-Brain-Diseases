{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8274d086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T22:47:20.384819Z",
     "iopub.status.busy": "2024-09-17T22:47:20.384277Z",
     "iopub.status.idle": "2024-09-17T22:47:30.614856Z",
     "shell.execute_reply": "2024-09-17T22:47:30.613802Z"
    },
    "papermill": {
     "duration": 10.239327,
     "end_time": "2024-09-17T22:47:30.617281",
     "exception": false,
     "start_time": "2024-09-17T22:47:20.377954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.15 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torchvision import models\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13e9af44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T22:47:30.628118Z",
     "iopub.status.busy": "2024-09-17T22:47:30.627220Z",
     "iopub.status.idle": "2024-09-17T22:47:30.638281Z",
     "shell.execute_reply": "2024-09-17T22:47:30.637193Z"
    },
    "papermill": {
     "duration": 0.018627,
     "end_time": "2024-09-17T22:47:30.640555",
     "exception": false,
     "start_time": "2024-09-17T22:47:30.621928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix\n",
    "from PIL import Image\n",
    "import shutil\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "437d9091",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T22:47:30.650755Z",
     "iopub.status.busy": "2024-09-17T22:47:30.649860Z",
     "iopub.status.idle": "2024-09-17T22:47:42.765987Z",
     "shell.execute_reply": "2024-09-17T22:47:42.764613Z"
    },
    "papermill": {
     "duration": 12.123835,
     "end_time": "2024-09-17T22:47:42.768472",
     "exception": false,
     "start_time": "2024-09-17T22:47:30.644637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of benign files: 45855\n",
      "Number of malignant files: 6466\n"
     ]
    }
   ],
   "source": [
    "def get_file_paths(directory):\n",
    "    return [os.path.join(dirpath, f) for dirpath, _, filenames in os.walk(directory) for f in filenames if f.endswith('.jpg')]\n",
    "\n",
    "benign_dir = \"/kaggle/input/iaaa-mri-train-data-partition/iaaa-mri-train-data partition/data/benign\"\n",
    "malignant_dir = \"/kaggle/input/iaaa-mri-train-data-partition/iaaa-mri-train-data partition/data/malignant\"\n",
    "\n",
    "benign_files = get_file_paths(benign_dir)\n",
    "malignant_files = get_file_paths(malignant_dir)\n",
    "\n",
    "benign_labels = [0] * len(benign_files)\n",
    "malignant_labels = [1] * len(malignant_files)\n",
    "\n",
    "file_paths = benign_files + malignant_files\n",
    "labels = benign_labels + malignant_labels\n",
    "\n",
    "df = pd.DataFrame({\"file_path\": file_paths, \"label\": labels})\n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "print(f\"Number of benign files: {len(benign_files)}\")\n",
    "print(f\"Number of malignant files: {len(malignant_files)}\")\n",
    "\n",
    "if len(benign_files) == 0 or len(malignant_files) == 0:\n",
    "    raise ValueError(\"No image files found in one or both directories. Please check the file paths.\")\n",
    "\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "file_paths_resampled, labels_resampled = oversampler.fit_resample(\n",
    "    train_df['file_path'].values.reshape(-1, 1),\n",
    "    train_df['label']\n",
    ")\n",
    "train_df_resampled = pd.DataFrame({\"file_path\": file_paths_resampled.flatten(), \"label\": labels_resampled})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07de135a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T22:47:42.778957Z",
     "iopub.status.busy": "2024-09-17T22:47:42.778556Z",
     "iopub.status.idle": "2024-09-18T04:44:34.573617Z",
     "shell.execute_reply": "2024-09-18T04:44:34.572106Z"
    },
    "papermill": {
     "duration": 21411.803223,
     "end_time": "2024-09-18T04:44:34.575965",
     "exception": false,
     "start_time": "2024-09-17T22:47:42.772742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 167MB/s]\n",
      "Epoch 1/60: 100%|██████████| 2007/2007 [05:42<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "Train Loss: 0.8245, Train Accuracy: 0.6231\n",
      "Val Loss: 0.7823, Val Accuracy: 0.7081\n",
      "Val Precision: 0.2372, Val Recall: 0.6144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/60\n",
      "Train Loss: 0.7893, Train Accuracy: 0.6728\n",
      "Val Loss: 0.7682, Val Accuracy: 0.7043\n",
      "Val Precision: 0.2490, Val Recall: 0.6907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/60\n",
      "Train Loss: 0.7655, Train Accuracy: 0.6971\n",
      "Val Loss: 0.6812, Val Accuracy: 0.7812\n",
      "Val Precision: 0.3090, Val Recall: 0.6227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/60\n",
      "Train Loss: 0.7416, Train Accuracy: 0.7204\n",
      "Val Loss: 0.6588, Val Accuracy: 0.7901\n",
      "Val Precision: 0.3199, Val Recall: 0.6196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/60\n",
      "Train Loss: 0.7164, Train Accuracy: 0.7427\n",
      "Val Loss: 0.7133, Val Accuracy: 0.7418\n",
      "Val Precision: 0.2977, Val Recall: 0.8010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/60\n",
      "Train Loss: 0.6963, Train Accuracy: 0.7613\n",
      "Val Loss: 0.5801, Val Accuracy: 0.8499\n",
      "Val Precision: 0.4231, Val Recall: 0.5897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/60\n",
      "Train Loss: 0.6759, Train Accuracy: 0.7777\n",
      "Val Loss: 0.5779, Val Accuracy: 0.8540\n",
      "Val Precision: 0.4429, Val Recall: 0.7041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/60\n",
      "Train Loss: 0.6566, Train Accuracy: 0.7919\n",
      "Val Loss: 0.5555, Val Accuracy: 0.8675\n",
      "Val Precision: 0.4719, Val Recall: 0.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/60\n",
      "Train Loss: 0.6388, Train Accuracy: 0.8053\n",
      "Val Loss: 0.5307, Val Accuracy: 0.8872\n",
      "Val Precision: 0.5382, Val Recall: 0.6175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/60\n",
      "Train Loss: 0.6241, Train Accuracy: 0.8172\n",
      "Val Loss: 0.5118, Val Accuracy: 0.8986\n",
      "Val Precision: 0.5935, Val Recall: 0.5691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/60\n",
      "Train Loss: 0.6099, Train Accuracy: 0.8284\n",
      "Val Loss: 0.5257, Val Accuracy: 0.8857\n",
      "Val Precision: 0.5278, Val Recall: 0.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/60\n",
      "Train Loss: 0.5990, Train Accuracy: 0.8346\n",
      "Val Loss: 0.5148, Val Accuracy: 0.8955\n",
      "Val Precision: 0.5698, Val Recall: 0.6309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/60\n",
      "Train Loss: 0.5875, Train Accuracy: 0.8449\n",
      "Val Loss: 0.5134, Val Accuracy: 0.9010\n",
      "Val Precision: 0.5862, Val Recall: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/60\n",
      "Train Loss: 0.5774, Train Accuracy: 0.8515\n",
      "Val Loss: 0.5186, Val Accuracy: 0.8941\n",
      "Val Precision: 0.5556, Val Recall: 0.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/60\n",
      "Train Loss: 0.5660, Train Accuracy: 0.8592\n",
      "Val Loss: 0.4919, Val Accuracy: 0.9132\n",
      "Val Precision: 0.6413, Val Recall: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/60\n",
      "Train Loss: 0.5588, Train Accuracy: 0.8637\n",
      "Val Loss: 0.4997, Val Accuracy: 0.9123\n",
      "Val Precision: 0.6343, Val Recall: 0.6866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/60\n",
      "Train Loss: 0.5471, Train Accuracy: 0.8717\n",
      "Val Loss: 0.5221, Val Accuracy: 0.8973\n",
      "Val Precision: 0.5618, Val Recall: 0.7680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/60\n",
      "Train Loss: 0.5412, Train Accuracy: 0.8751\n",
      "Val Loss: 0.5131, Val Accuracy: 0.9051\n",
      "Val Precision: 0.5966, Val Recall: 0.7165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60\n",
      "Train Loss: 0.5305, Train Accuracy: 0.8831\n",
      "Val Loss: 0.4848, Val Accuracy: 0.9173\n",
      "Val Precision: 0.6600, Val Recall: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/60\n",
      "Train Loss: 0.5214, Train Accuracy: 0.8896\n",
      "Val Loss: 0.5155, Val Accuracy: 0.9060\n",
      "Val Precision: 0.5981, Val Recall: 0.7289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/60\n",
      "Train Loss: 0.5184, Train Accuracy: 0.8917\n",
      "Val Loss: 0.4715, Val Accuracy: 0.9314\n",
      "Val Precision: 0.7584, Val Recall: 0.6536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/60\n",
      "Train Loss: 0.5135, Train Accuracy: 0.8945\n",
      "Val Loss: 0.4884, Val Accuracy: 0.9178\n",
      "Val Precision: 0.6465, Val Recall: 0.7392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/60\n",
      "Train Loss: 0.5048, Train Accuracy: 0.8995\n",
      "Val Loss: 0.4698, Val Accuracy: 0.9300\n",
      "Val Precision: 0.7301, Val Recall: 0.6887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/60\n",
      "Train Loss: 0.5025, Train Accuracy: 0.9009\n",
      "Val Loss: 0.4852, Val Accuracy: 0.9307\n",
      "Val Precision: 0.7950, Val Recall: 0.5918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      "Train Loss: 0.4929, Train Accuracy: 0.9080\n",
      "Val Loss: 0.4690, Val Accuracy: 0.9300\n",
      "Val Precision: 0.7062, Val Recall: 0.7433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/60\n",
      "Train Loss: 0.4881, Train Accuracy: 0.9109\n",
      "Val Loss: 0.4756, Val Accuracy: 0.9318\n",
      "Val Precision: 0.7254, Val Recall: 0.7216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/60\n",
      "Train Loss: 0.4849, Train Accuracy: 0.9133\n",
      "Val Loss: 0.4752, Val Accuracy: 0.9309\n",
      "Val Precision: 0.7229, Val Recall: 0.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/60\n",
      "Train Loss: 0.4777, Train Accuracy: 0.9169\n",
      "Val Loss: 0.4786, Val Accuracy: 0.9322\n",
      "Val Precision: 0.7697, Val Recall: 0.6443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/60\n",
      "Train Loss: 0.4734, Train Accuracy: 0.9188\n",
      "Val Loss: 0.4659, Val Accuracy: 0.9405\n",
      "Val Precision: 0.7983, Val Recall: 0.6938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/60\n",
      "Train Loss: 0.4698, Train Accuracy: 0.9223\n",
      "Val Loss: 0.4710, Val Accuracy: 0.9304\n",
      "Val Precision: 0.7054, Val Recall: 0.7505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/60\n",
      "Train Loss: 0.4645, Train Accuracy: 0.9243\n",
      "Val Loss: 0.4725, Val Accuracy: 0.9407\n",
      "Val Precision: 0.8435, Val Recall: 0.6392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/60\n",
      "Train Loss: 0.4613, Train Accuracy: 0.9267\n",
      "Val Loss: 0.4760, Val Accuracy: 0.9346\n",
      "Val Precision: 0.7783, Val Recall: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/60\n",
      "Train Loss: 0.4575, Train Accuracy: 0.9290\n",
      "Val Loss: 0.4747, Val Accuracy: 0.9405\n",
      "Val Precision: 0.8508, Val Recall: 0.6289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/60\n",
      "Train Loss: 0.4543, Train Accuracy: 0.9307\n",
      "Val Loss: 0.4630, Val Accuracy: 0.9411\n",
      "Val Precision: 0.8299, Val Recall: 0.6588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/60\n",
      "Train Loss: 0.4495, Train Accuracy: 0.9345\n",
      "Val Loss: 0.4721, Val Accuracy: 0.9418\n",
      "Val Precision: 0.8268, Val Recall: 0.6691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/60\n",
      "Train Loss: 0.4479, Train Accuracy: 0.9348\n",
      "Val Loss: 0.4679, Val Accuracy: 0.9346\n",
      "Val Precision: 0.7353, Val Recall: 0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/60\n",
      "Train Loss: 0.4436, Train Accuracy: 0.9371\n",
      "Val Loss: 0.4532, Val Accuracy: 0.9419\n",
      "Val Precision: 0.7769, Val Recall: 0.7433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/60\n",
      "Train Loss: 0.4405, Train Accuracy: 0.9388\n",
      "Val Loss: 0.4503, Val Accuracy: 0.9448\n",
      "Val Precision: 0.8200, Val Recall: 0.7093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/60\n",
      "Train Loss: 0.4388, Train Accuracy: 0.9394\n",
      "Val Loss: 0.4633, Val Accuracy: 0.9407\n",
      "Val Precision: 0.8083, Val Recall: 0.6825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/60\n",
      "Train Loss: 0.4343, Train Accuracy: 0.9429\n",
      "Val Loss: 0.4649, Val Accuracy: 0.9415\n",
      "Val Precision: 0.7933, Val Recall: 0.7124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/60\n",
      "Train Loss: 0.4329, Train Accuracy: 0.9432\n",
      "Val Loss: 0.4826, Val Accuracy: 0.9406\n",
      "Val Precision: 0.8975, Val Recall: 0.5866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/60\n",
      "Train Loss: 0.4296, Train Accuracy: 0.9457\n",
      "Val Loss: 0.4588, Val Accuracy: 0.9452\n",
      "Val Precision: 0.8325, Val Recall: 0.6969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/60\n",
      "Train Loss: 0.4282, Train Accuracy: 0.9463\n",
      "Val Loss: 0.4629, Val Accuracy: 0.9419\n",
      "Val Precision: 0.7818, Val Recall: 0.7351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/60\n",
      "Train Loss: 0.4260, Train Accuracy: 0.9473\n",
      "Val Loss: 0.4572, Val Accuracy: 0.9432\n",
      "Val Precision: 0.7829, Val Recall: 0.7474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/60\n",
      "Train Loss: 0.4229, Train Accuracy: 0.9492\n",
      "Val Loss: 0.4548, Val Accuracy: 0.9447\n",
      "Val Precision: 0.8392, Val Recall: 0.6835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/60\n",
      "Train Loss: 0.4196, Train Accuracy: 0.9513\n",
      "Val Loss: 0.4633, Val Accuracy: 0.9447\n",
      "Val Precision: 0.8418, Val Recall: 0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/60\n",
      "Train Loss: 0.4191, Train Accuracy: 0.9523\n",
      "Val Loss: 0.4541, Val Accuracy: 0.9467\n",
      "Val Precision: 0.8511, Val Recall: 0.6897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/60\n",
      "Train Loss: 0.4182, Train Accuracy: 0.9513\n",
      "Val Loss: 0.4777, Val Accuracy: 0.9434\n",
      "Val Precision: 0.8603, Val Recall: 0.6474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/60\n",
      "Train Loss: 0.4148, Train Accuracy: 0.9542\n",
      "Val Loss: 0.4677, Val Accuracy: 0.9441\n",
      "Val Precision: 0.8084, Val Recall: 0.7175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/60\n",
      "Train Loss: 0.4147, Train Accuracy: 0.9533\n",
      "Val Loss: 0.4453, Val Accuracy: 0.9508\n",
      "Val Precision: 0.8460, Val Recall: 0.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/60\n",
      "Train Loss: 0.4110, Train Accuracy: 0.9569\n",
      "Val Loss: 0.4544, Val Accuracy: 0.9448\n",
      "Val Precision: 0.8429, Val Recall: 0.6804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/60\n",
      "Train Loss: 0.4096, Train Accuracy: 0.9571\n",
      "Val Loss: 0.4594, Val Accuracy: 0.9474\n",
      "Val Precision: 0.8384, Val Recall: 0.7113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/60\n",
      "Train Loss: 0.4084, Train Accuracy: 0.9578\n",
      "Val Loss: 0.4562, Val Accuracy: 0.9474\n",
      "Val Precision: 0.8530, Val Recall: 0.6938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/60\n",
      "Train Loss: 0.4049, Train Accuracy: 0.9605\n",
      "Val Loss: 0.4531, Val Accuracy: 0.9493\n",
      "Val Precision: 0.8365, Val Recall: 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/60: 100%|██████████| 2007/2007 [05:40<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/60\n",
      "Train Loss: 0.4061, Train Accuracy: 0.9591\n",
      "Val Loss: 0.4470, Val Accuracy: 0.9502\n",
      "Val Precision: 0.8642, Val Recall: 0.7082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/60: 100%|██████████| 2007/2007 [05:38<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/60\n",
      "Train Loss: 0.4037, Train Accuracy: 0.9602\n",
      "Val Loss: 0.4628, Val Accuracy: 0.9465\n",
      "Val Precision: 0.8362, Val Recall: 0.7052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/60\n",
      "Train Loss: 0.4009, Train Accuracy: 0.9624\n",
      "Val Loss: 0.4434, Val Accuracy: 0.9507\n",
      "Val Precision: 0.8301, Val Recall: 0.7557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "Train Loss: 0.4008, Train Accuracy: 0.9624\n",
      "Val Loss: 0.4508, Val Accuracy: 0.9453\n",
      "Val Precision: 0.7634, Val Recall: 0.8082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/60\n",
      "Train Loss: 0.3997, Train Accuracy: 0.9631\n",
      "Val Loss: 0.4413, Val Accuracy: 0.9511\n",
      "Val Precision: 0.8488, Val Recall: 0.7351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/60: 100%|██████████| 2007/2007 [05:39<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/60\n",
      "Train Loss: 0.3972, Train Accuracy: 0.9645\n",
      "Val Loss: 0.4467, Val Accuracy: 0.9498\n",
      "Val Precision: 0.8445, Val Recall: 0.7278\n",
      "Best validation recall: 0.8082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:20<00:00, 11.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model performance:\n",
      "TN: 6633, FP: 246, FN: 197, TP: 773\n",
      "\n",
      "Test Accuracy: 0.9436\n",
      "Test Precision: 0.7586\n",
      "Test Recall: 0.7969\n",
      "Test F1-Score: 0.7773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "        return F_loss.mean()\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.unsqueeze(1).long(), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, smoothing=0.1, classes=2):\n",
    "        super().__init__()\n",
    "        self.focal_loss = FocalLoss(alpha, gamma)\n",
    "        self.label_smoothing = LabelSmoothingLoss(classes, smoothing)\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # For LabelSmoothingLoss, we need to keep the [batch_size, 2] shape\n",
    "        ls_loss = self.label_smoothing(inputs, targets.long())\n",
    "        \n",
    "        # For FocalLoss, we need to use the probability of the positive class\n",
    "        focal_loss = self.focal_loss(inputs[:, 1], targets.float())\n",
    "        \n",
    "        return ls_loss + focal_loss\n",
    "    \n",
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['file_path']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "def create_transforms():\n",
    "    train_transform = A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.Flip(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, fill_value=0, p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    val_transform = A.Compose([\n",
    "        A.Resize(224, 224),\n",
    "        A.Flip(p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "\n",
    "    return train_transform, val_transform\n",
    "\n",
    "class AttentionGate(nn.Module):\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(AttentionGate, self).__init__()\n",
    "        self.W_g = nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.W_x = nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.psi = nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        if g1.shape != x1.shape:\n",
    "            g1 = F.interpolate(g1, size=x1.shape[2:], mode='bilinear', align_corners=False)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        return x * self.sigmoid(psi)\n",
    "\n",
    "class BrainTumorModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainTumorModel, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=True)\n",
    "        self.attention1 = AttentionGate(2048, 1024, 512)\n",
    "        self.attention2 = AttentionGate(2048, 512, 256)\n",
    "        self.attention3 = AttentionGate(2048, 256, 128)\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet.conv1(x)\n",
    "        x = self.resnet.bn1(x)\n",
    "        x = self.resnet.relu(x)\n",
    "        x = self.resnet.maxpool(x)\n",
    "\n",
    "        x1 = self.resnet.layer1(x)\n",
    "        x2 = self.resnet.layer2(x1)\n",
    "        x3 = self.resnet.layer3(x2)\n",
    "        x4 = self.resnet.layer4(x3)\n",
    "\n",
    "        x3 = self.attention1(x4, x3)\n",
    "        x2 = self.attention2(x4, x2)\n",
    "        x1 = self.attention3(x4, x1)\n",
    "\n",
    "        x = self.global_pool(x4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def test_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(test_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            labels.extend(targets.numpy())\n",
    "    return predictions, labels\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, scaler):\n",
    "    best_val_recall = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_preds = torch.argmax(outputs, dim=1)\n",
    "            train_correct += (train_preds == labels.long()).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_preds = []\n",
    "        val_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                val_correct += (preds == labels.long()).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_true.extend(labels.cpu().numpy())\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_loss /= len(val_loader)\n",
    "        val_precision = precision_score(val_true, val_preds)\n",
    "        val_recall = recall_score(val_true, val_preds)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Val Precision: {val_precision:.4f}, Val Recall: {val_recall:.4f}\")\n",
    "\n",
    "        if val_recall > best_val_recall:\n",
    "            best_val_recall = val_recall\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    print(f\"Best validation recall: {best_val_recall:.4f}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_transform, val_transform = create_transforms()\n",
    "\n",
    "train_dataset = BrainDataset(train_df_resampled, transform=train_transform)\n",
    "val_dataset = BrainDataset(val_df, transform=val_transform)\n",
    "test_dataset = BrainDataset(test_df, transform=val_transform)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "model = BrainTumorModel().to(device)\n",
    "\n",
    "criterion = CombinedLoss(alpha=1, gamma=2, smoothing=0.1, classes=2)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "num_epochs = 60\n",
    "steps_per_epoch = len(train_loader)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=1e-3, epochs=num_epochs, steps_per_epoch=steps_per_epoch)\n",
    "scaler = GradScaler()\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, scaler)\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "predictions, labels = test_model(model, test_loader, device)\n",
    "\n",
    "new_list = [0 if value <= 0.50 else 1 for value in predictions]\n",
    "cf = confusion_matrix(labels, new_list)\n",
    "tn, fp, fn, tp = cf.ravel()\n",
    "print(f\"\\nModel performance:\\nTN: {tn}, FP: {fp}, FN: {fn}, TP: {tp}\\n\")\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1-Score: {f1_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31b9b7ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-18T04:44:57.030233Z",
     "iopub.status.busy": "2024-09-18T04:44:57.029334Z",
     "iopub.status.idle": "2024-09-18T04:45:15.390010Z",
     "shell.execute_reply": "2024-09-18T04:45:15.388140Z"
    },
    "papermill": {
     "duration": 29.578109,
     "end_time": "2024-09-18T04:45:15.392132",
     "exception": true,
     "start_time": "2024-09-18T04:44:45.814023",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 246/246 [00:17<00:00, 14.02it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [7849, 15698]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m     avg_f1 \u001b[38;5;241m=\u001b[39m f1_score(all_labels, binary_preds)\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc, fpr, tpr, precision, recall, ap, avg_recall, avg_f1, all_preds, all_labels\n\u001b[0;32m---> 34\u001b[0m auc, fpr, tpr, precision, recall, ap, avg_recall, avg_f1, all_preds, all_labels \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mauc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverage Precision: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00map\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, dataloader, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m all_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_preds)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     18\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(all_labels)\n\u001b[0;32m---> 20\u001b[0m auc \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m roc_curve(all_labels, all_preds)\n\u001b[1;32m     23\u001b[0m precision, recall, thresholds \u001b[38;5;241m=\u001b[39m precision_recall_curve(all_labels, all_preds)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:572\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n\u001b[1;32m    571\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m label_binarize(y_true, classes\u001b[38;5;241m=\u001b[39mlabels)[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_average_binary_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_binary_roc_auc_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_fpr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_fpr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# multilabel-indicator\u001b[39;00m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    581\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[38;5;241m=\u001b[39mmax_fpr),\n\u001b[1;32m    582\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    585\u001b[0m         sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m    586\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_base.py:75\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_metric\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m check_consistent_length(y_true, y_score, sample_weight)\n\u001b[1;32m     78\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:344\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y_true)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not defined in that case.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[0;32m--> 344\u001b[0m fpr, tpr, _ \u001b[38;5;241m=\u001b[39m \u001b[43mroc_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m max_fpr \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m auc(fpr, tpr)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:992\u001b[0m, in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mroc_curve\u001b[39m(\n\u001b[1;32m    905\u001b[0m     y_true, y_score, \u001b[38;5;241m*\u001b[39m, pos_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, drop_intermediate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    906\u001b[0m ):\n\u001b[1;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Receiver operating characteristic (ROC).\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;124;03m    array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])\u001b[39;00m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 992\u001b[0m     fps, tps, thresholds \u001b[38;5;241m=\u001b[39m \u001b[43m_binary_clf_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;66;03m# Attempt to drop thresholds corresponding to points in between and\u001b[39;00m\n\u001b[1;32m    997\u001b[0m     \u001b[38;5;66;03m# collinear with other points. These are always suboptimal and do not\u001b[39;00m\n\u001b[1;32m    998\u001b[0m     \u001b[38;5;66;03m# appear on a plotted ROC curve (and thus do not affect the AUC).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1003\u001b[0m     \u001b[38;5;66;03m# but does not drop more complicated cases like fps = [1, 3, 7],\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m     \u001b[38;5;66;03m# tps = [1, 2, 4]; there is no harm in keeping too many thresholds.\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m drop_intermediate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fps) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:751\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m format is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(y_type))\n\u001b[0;32m--> 751\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m y_true \u001b[38;5;241m=\u001b[39m column_or_1d(y_true)\n\u001b[1;32m    753\u001b[0m y_score \u001b[38;5;241m=\u001b[39m column_or_1d(y_score)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:397\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7849, 15698]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve, average_precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            probabilities = torch.sigmoid(outputs)\n",
    "            all_preds.extend(probabilities.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds).flatten()\n",
    "    all_labels = np.array(all_labels)\n",
    "    \n",
    "    auc = roc_auc_score(all_labels, all_preds)\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_preds)\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(all_labels, all_preds)\n",
    "    \n",
    "    ap = average_precision_score(all_labels, all_preds)\n",
    "    \n",
    "    binary_preds = (all_preds >= 0.5).astype(int)\n",
    "    avg_recall = recall_score(all_labels, binary_preds)\n",
    "    \n",
    "    avg_f1 = f1_score(all_labels, binary_preds)\n",
    "\n",
    "    return auc, fpr, tpr, precision, recall, ap, avg_recall, avg_f1, all_preds, all_labels\n",
    "\n",
    "auc, fpr, tpr, precision, recall, ap, avg_recall, avg_f1, all_preds, all_labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"Average Precision: {ap:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score (Precision-Recall): {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cbdce8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T08:36:39.785272Z",
     "iopub.status.busy": "2024-09-14T08:36:39.784443Z",
     "iopub.status.idle": "2024-09-14T08:36:40.350069Z",
     "shell.execute_reply": "2024-09-14T08:36:40.349002Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f'Precision-Recall curve (AP = {ap:.2f})')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "thresholds = [0.3, 0.5, 0.7]\n",
    "for threshold in thresholds:\n",
    "    y_pred = (all_preds >= threshold).astype(int)\n",
    "    true_positives = np.sum((y_pred == 1) & (all_labels == 1))\n",
    "    false_positives = np.sum((y_pred == 1) & (all_labels == 0))\n",
    "    false_negatives = np.sum((y_pred == 0) & (all_labels == 1))\n",
    "    \n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    \n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697da2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-14T08:36:59.927831Z",
     "iopub.status.busy": "2024-09-14T08:36:59.927090Z",
     "iopub.status.idle": "2024-09-14T08:37:05.299426Z",
     "shell.execute_reply": "2024-09-14T08:37:05.298466Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.load_state_dict(torch.load('/kaggle/working/best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "random_indices = random.sample(range(len(test_dataset)), 50)\n",
    "\n",
    "random_loader = DataLoader([test_dataset[i] for i in random_indices], batch_size=1, shuffle=False)\n",
    "\n",
    "predictions = []\n",
    "true_labels = []\n",
    "images = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for image, label in random_loader:\n",
    "        image = image.to(device)\n",
    "        output = model(image)\n",
    "        pred = torch.sigmoid(output).cpu().numpy()[0][0]\n",
    "        predictions.append(pred)\n",
    "        true_labels.append(label.item())\n",
    "        \n",
    "        images.append(image.cpu().squeeze().permute(1, 2, 0).numpy())\n",
    "\n",
    "auc = roc_auc_score(true_labels, predictions)\n",
    "print(f\"AUC for 50 random images: {auc:.4f}\")\n",
    "\n",
    "fig, axes = plt.subplots(10, 5, figsize=(20, 40))\n",
    "fig.suptitle(f\"50 Random Images with Predictions (AUC: {auc:.4f})\", fontsize=16)\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(images):\n",
    "        ax.imshow(images[i], cmap='gray')\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "        pred_class = 1 if predictions[i] > 0.5 else 0\n",
    "        correct = (pred_class == true_labels[i])\n",
    "        title_color = 'green' if correct else 'red'\n",
    "\n",
    "        title = f\"True: {true_labels[i]}\\nPred: {predictions[i]:.2f}\"\n",
    "        ax.set_title(title, color=title_color)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])  # Leave space for the suptitle\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5372944,
     "sourceId": 8931416,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5589804,
     "sourceId": 9240782,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21492.037655,
   "end_time": "2024-09-18T04:45:29.287737",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-17T22:47:17.250082",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
